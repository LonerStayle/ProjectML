{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca35364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path(os.getcwd()).resolve().parents[1]  \n",
    "sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8095d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/seobi/PythonProjects/ProjectML/src/agents/fairy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4163cbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents.fairy.fairy_state import FairyState, FairyOutput\n",
    "FairyState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4338f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seobi/PythonProjects/ProjectML/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from enums.LLM import LLM\n",
    "\n",
    "llm = init_chat_model(model=LLM.GPT4_1_MINI,temperature=0.4)\n",
    "# parser_llm = llm.with_structured_output(FairyOutput)\n",
    "\n",
    "# result = parser_llm.invoke(\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "# result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766e29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "from prompts.promptmanager import PromptManager\n",
    "from prompts.prompt_type.fairy.FairyPromptType import FairyPromptType\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from agents.fairy.temp_string import temp_heroine_info\n",
    "\n",
    "system_dungeon_prompt = PromptManager(FairyPromptType.FAIRY_DUNGEON_SYSTEM).get_prompt(\n",
    "    heroine_status = \"\"\"\n",
    "    ê³µê²©ë ¥ 10\n",
    "    ë°©ì–´ë ¥ 5\n",
    "    HP 40/100\n",
    "    MP 20/50\n",
    "    \"\"\",\n",
    "    heroine_info = temp_heroine_info,\n",
    "    dungeon_info = \"ì´ 4ì¸µìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë˜ì „ ë°©ì˜ ê°¯ìˆ˜ëŠ” ì¸µë‹¹ ê°ê° 5~7ê°œ ì‚¬ì´\",\n",
    "    event_info = \"\",\n",
    "    floor = \"2\",\n",
    "    level = \"ë‚œì´ë„ í•˜\",\n",
    "    current_room = \"ìŠ¬ë¼ì„ 3ë§ˆë¦¬, ìš¸í”„ 5ë§ˆë¦¬\"\n",
    ")\n",
    "result = llm.invoke([SystemMessage(content = system_dungeon_prompt)] + [HumanMessage(content = \"ìŠ¬ë¼ì„ ì–´ë–»ê²Œ ê³µê²©í•´?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a66c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŠ¬ë¼ì„ì€ ê³µê²©ë ¥ì´ ì•½í•˜ê³  ë°©ì–´ë ¥ì´ ë‚®ì•„ì„œ ê¸°ë³¸ ê³µê²©ìœ¼ë¡œë„ ì‰½ê²Œ ìƒëŒ€í•  ìˆ˜ ìˆì–´ìš”. ë‹¤ë§Œ, ìŠ¬ë¼ì„ì€ ë¶„ì—´í•˜ëŠ” ì„±ì§ˆì´ ìˆìœ¼ë‹ˆ í•œ ë²ˆì— ì—¬ëŸ¬ ë§ˆë¦¬ë¥¼ ê³µê²©í•˜ëŠ” ìŠ¤í‚¬ì´ë‚˜ ë²”ìœ„ ê³µê²©ì´ ìˆë‹¤ë©´ íš¨ê³¼ì ì´ì—ìš”. ë ˆí‹°ì•„, ìŒê²€ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì—°ì† ê³µê²©í•´ì„œ í•œ ë§ˆë¦¬ì”© í™•ì‹¤íˆ ì²˜ë¦¬í•˜ëŠ” ê²Œ ì•ˆì „í•  ê±°ì˜ˆìš”! ë„ˆë¬´ ì˜¤ë˜ ëŒë©´ ìŠ¬ë¼ì„ì´ ëŠ˜ì–´ë‚˜ì„œ ê³¨ì¹˜ ì•„íŒŒì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆê¹Œìš”~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5609799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_guild_prompt = PromptManager(FairyPromptType.FAIRY_GUILD_SYSTEM).get_prompt(\n",
    "    heroine_info = temp_heroine_info,\n",
    "    heroine_status = \"\"\"\n",
    "    ê³µê²©ë ¥ 10\n",
    "    ë°©ì–´ë ¥ 5\n",
    "    HP 40/100\n",
    "    MP 20/50\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38701618",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke([SystemMessage(content = system_guild_prompt)] + [HumanMessage(content = \"ë‚˜ ì‹¬ì‹¬í•´\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a85816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì–´ë¨¸, ì‹¬ì‹¬í•˜ë‹¤ë‹ˆ! ê·¸ëŸ¼ ë‚´ê°€ ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸° í•˜ë‚˜ ë“¤ë ¤ì¤„ê¹Œ? ì•„ë‹ˆë©´ ë ˆí‹°ì•„ë‘ ê°™ì´ ë˜ì „ íƒí—˜í•˜ë©´ì„œ ìˆ¨ê²¨ì§„ ë¹„ë°€ì„ ì°¾ì•„ë³¼ê¹Œ? ì•„ë‹ˆë©´ ê·¸ëƒ¥ ê°€ë²¼ìš´ ìˆ˜ë‹¤ë‚˜ í• ë˜? ë­ë“  ë§ë§Œ í•´ë´, ë‚´ê°€ ê³ì—ì„œ íŒíŒ ë„ì™€ì¤„ê²Œ! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a580cd",
   "metadata": {},
   "source": [
    "# ëª¬ìŠ¤í„° ê³µëµ (ì£¼ë¡œ ë³´ìŠ¤ëª¬ìŠ¤í„° ìœ„ì£¼ë¡œ)\n",
    " 1. í˜„ì¬ë°©ì˜ ëª¬ìŠ¤í„° ìƒì„¸ ì •ë³´ í•„ìš” -> ìƒì„¸ì •ë³´ Search RAG (K = 1)\n",
    " 2. ëª¬ìŠ¤í„° ì°¾ê¸° ë©€í‹°ì¿¼ë¦¬ í•„ìš” -> ì‚¬ìš©ìëŠ” ëª¬ìŠ¤í„° ëª…ì„ ëª¨ë¥¼ í™•ë¥ ì´ í¼ => ë©€í‹°ì¿¼ë¦¬ë¡œ í˜„ì¬ë°©ì¤‘ ëª¬ìŠ¤í„° íŠ¹ì§•ì— ë”°ë¼ ëª¬ìŠ¤í„° ì°¾ê¸°\n",
    " 3. ëª¬ìŠ¤í„° ê³µëµë²• RAG í•„ìš” -> ì°¾ì€ ëª¬ìŠ¤í„°ì˜ ê³µëµ í•´ê²°ì±…ì„ ì°¾ëŠ” ì„œì¹­ í•„ìš” \n",
    "\n",
    "# ì´ë²¤íŠ¸ ê³µëµ \n",
    " - ìºì‹œ DBë¡œë¶€í„° ìƒì„±ëœ ì´ë²¤íŠ¸ ì •ë³´ GET -> íŒíŠ¸ ìœ„ì£¼ë¡œ ì œê³µ \n",
    "\n",
    "# ë˜ì „ ì•ˆë‚´\n",
    " - ìºì‹œ DBë¡œ ë¶€í„° ìƒì„±ëœ ë˜ì „ì˜ ì „ì²´ íŠ¹ì§•ì„ ìš”ì•½ í›„ ë¸Œë¦¬í•‘ \n",
    "\n",
    "# ì¸í„°ë ‰ì…˜ \n",
    " - ë°© ë¶ˆí‚¤ê¸°, ë¬¼ì•½ ì‚¬ìš©, ì•„ì´í…œ ì‚¬ìš© return ì•¡ì…˜, ì‚¬ìš©ID(Option)\n",
    "\n",
    "# ë©€í‹°í„´ ì „ëµ \n",
    " - ì´ì „ ëŒ€í™” ìš”ì•½ë³¸ ì €ì¥ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457ebcb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
